# 3. 확률(Probability) 분포

## Contents

- **3.1 확률(Probability) 정의 및 개념**
- **3.2 확률(Probability) 규칙 및 정의**
- **3.3 확률(Probability) 변수 및 분포**
- **3.4 기대값 및 분산 (Expected Value and Variance)**
- **3.5 다변수 확률 변수 (Multivariate Random Variables)**

---
## 3.1 확률(Probability) 정의 및 개념

### 3.1.1 확률 (Probability)

확률은 무작위 실험에서 특정 결과가 발생할 가능성을 수치로 나타낸 것입니다. 표본 공간 S에 속한 어떤 결과 e에 대해, 확률 P는 0과 1 사이의 값을 가지며 해당 결과가 단일 시행에서 발생할 가능성을 측정합니다.

확률값이 $P = 0$이라는 것은 그 결과가 발생하는 것이 불가능함을 의미하고, $P = 1$은 그 결과가 반드시 발생함을 의미합니다. 예를 들어, 공정한 동전을 던질 때 앞면이 나올 확률은 0.5이며, 이는 앞면과 뒷면이 나올 가능성이 동일함을 나타냅니다.

사건 A의 확률은 그 사건을 구성하는 개별 결과들의 확률을 모두 합한 값으로 정의되며, $P(A)$로 표기합니다. 이러한 확률의 정의는 통계적 추론과 데이터 분석의 기초가 됩니다.

### 3.1.2 표본 공간 및 사건 (Sample Space & Events)

표본 공간(Sample Space, S)은 무작위 현상에서 발생 가능한 모든 결과의 집합입니다. 무작위 실험을 수행할 때 나타날 수 있는 모든 가능성을 포함하는 전체 집합이라고 할 수 있습니다.

사건(Event)은 표본 공간의 부분집합입니다. 즉, 전체 가능한 결과들 중에서 우리가 관심있는 특정 결과들의 모임을 의미합니다. 동전을 세 번 던지는 실험을 예로 들면, 표본 공간은 $S = {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT}$가 됩니다. 여기서 H는 앞면(Heads), T는 뒷면(Tails)을 나타냅니다.

이 표본 공간에서 다양한 사건을 정의할 수 있습니다. "모두 앞면이 나오는 사건"은 ${HHH}$로 표현되며, "정확히 한 번만 앞면이 나오는 사건"은 ${HTT, THT, TTH}$가 됩니다. 또한 "최소 두 번 이상 앞면이 나오는 사건"은 ${HHT, HTH, THH, HHH}$로 나타낼 수 있습니다. 이처럼 사건은 분석하고자 하는 관심사에 따라 다양하게 정의됩니다.

### 3.1.3 사건 간 관계

사건들 사이에는 여러 가지 관계가 존재하며, 이를 집합론의 개념을 통해 표현할 수 있습니다.

**여집합(Complement)** 은 사건 A가 발생하지 않는 경우를 나타내며, $A^c$ 또는 $(not A)$로 표기합니다. 동전을 세 번 던져서 적어도 한 번 앞면이 나올 확률을 구할 때, 여집합을 이용하면 계산이 훨씬 간단해집니다. "적어도 한 번 앞면"의 여집합은 "모두 뒷면"이므로, $P(A) = 1 - P(A^c) = 1 - 1/8 = 7/8$이 됩니다.

**교집합(Intersection)** 은 사건 A와 B가 동시에 발생하는 경우를 의미하며, $A ∩ B$ 또는 (A and B)로 표기합니다. 예를 들어, 카드 한 장을 뽑을 때 "킹이 나오는 사건"과 "스페이드가 나오는 사건"의 교집합은 "스페이드 킹"이 됩니다.

**합집합(Union)** 은 사건 A 또는 B 중 적어도 하나가 발생하는 경우를 나타내며, $A ∪ B$ 또는 (A or B)로 표기합니다. "에이스가 나오거나 하트가 나오는 사건"은 에이스 4장과 나머지 하트 12장을 모두 포함합니다.

**서로 배반인 사건(Disjoint Events)** 또는 상호배타적 사건(Mutually Exclusive Events)은 두 사건이 동시에 발생할 수 없는 경우를 말합니다. 동전을 한 번 던질 때 "앞면이 나오는 사건"과 "뒷면이 나오는 사건"은 서로 배반입니다. 마찬가지로 "시험에 합격하는 사건"과 "시험에 불합격하는 사건"도 서로 배반입니다. 카드 한 장을 뽑을 때 "에이스를 뽑는 사건"과 "퀸을 뽑는 사건"은 동시에 일어날 수 없으므로 배반 사건입니다.

반대로 서로 배반이 아닌 사건(Non-disjoint Events)은 동시에 발생할 수 있는 사건들입니다. "A학생이 통계 과목에서 A를 받는 사건"과 "B학생이 다른 과목에서 A를 받는 사건"은 독립적으로 동시에 발생할 수 있으므로 배반 사건이 아닙니다.

---
## 3.2 확률(Probability) 규칙 및 정의

### 3.2.1 덧셈 규칙

덧셈 규칙은 두 사건 중 적어도 하나가 발생할 확률을 계산하는 방법입니다. 카드 한 벌에서 임의로 한 장을 뽑을 때 잭(Jack)이 나오거나 빨간색 카드가 나올 확률을 구한다고 가정해봅시다. 이 경우 단순히 각각의 확률을 더하면 중복 계산이 발생합니다. 왜냐하면 빨간색 잭(하트 잭과 다이아몬드 잭)은 두 사건에 모두 포함되기 때문입니다.

따라서 덧셈 규칙은 다음과 같이 표현됩니다.

$$P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and } B)$$

앞서 언급한 예시에서 잭이 나올 확률은 $P(\text{jack}) = \frac{4}{52}$이고, 빨간색 카드가 나올 확률은 $P(\text{red}) = \frac{26}{52}$입니다. 그런데 빨간색 잭은 2장이므로 $P(\text{jack and red}) = \frac{2}{52}$입니다. 따라서 잭이거나 빨간색 카드가 나올 확률은 $\frac{4}{52} + \frac{26}{52} - \frac{2}{52} = \frac{28}{52}$가 됩니다. 이렇게 교집합 부분을 빼주는 것이 덧셈 규칙의 핵심입니다.

### 3.2.2 여사건 규칙

여사건 규칙은 어떤 사건이 발생하지 않을 확률을 이용하여 그 사건이 발생할 확률을 구하는 방법입니다. 모든 사건은 발생하거나 발생하지 않거나 둘 중 하나이므로, 사건 A와 그 여사건 $A^c$의 확률을 합하면 항상 1이 됩니다.

$$P(A) + P(A^c) = 1$$

따라서 다음과 같이 정리할 수 있습니다.

$$P(A^c) = 1 - P(A)$$

동전을 세 번 던져서 적어도 한 번 앞면이 나올 확률을 구하는 문제를 생각해봅시다. "적어도 한 번 앞면"이라는 사건은 7가지 경우를 모두 세어야 하지만, 그 여사건인 "모두 뒷면"은 {TTT} 단 한 가지 경우만 고려하면 됩니다. 따라서 $P(\text{all tails}) = \frac{1}{8}$이므로, $P(\text{at least one heads}) = 1 - \frac{1}{8} = \frac{7}{8}$로 간단하게 계산할 수 있습니다. 이처럼 여사건 규칙은 복잡한 계산을 단순화하는 데 매우 유용합니다.

### 3.2.3 조건부 확률

조건부 확률은 특정 사건 B가 이미 발생했다는 조건하에서 사건 A가 발생할 확률을 의미하며, $P(A|B)$로 표기합니다. 이는 "B가 주어졌을 때 A의 확률"로 읽습니다.

조건부 확률의 정의는 다음과 같습니다.

$$P(A|B) = \frac{P(A \text{ and } B)}{P(B)}$$

카드 한 벌에서 한 장을 뽑았을 때 그 카드가 킹일 확률은 $P(\text{King}) = \frac{4}{52}$입니다. 그런데 만약 뽑은 카드가 페이스 카드(Jack, Queen, King)라는 정보를 알게 되면, 표본 공간이 52장에서 12장으로 축소됩니다. 이제 킹일 확률은 $P(\text{King}|\text{face card}) = \frac{4}{12}$가 되며, 이는 처음 확률 $\frac{4}{52}$와 다릅니다. 이처럼 조건부 확률은 주어진 정보가 표본 공간을 제한함으로써 확률을 변화시킵니다.

나이와 단계별 분류 데이터가 주어졌을 때, 40세 미만이 선택되었다는 조건하에서 A단계일 확률을 $P(A|<40) = \frac{54}{470}$로 계산합니다. 범주형 변수가 하나만 포함된 확률을 주변 확률(marginal probability)이라 하고, 범주형 변수의 조합을 나타낸 확률을 결합 확률(joint probability)이라 하며, 특정 조건이 주어졌을 때의 확률을 조건부 확률(conditional probability)이라 합니다.

### 3.2.4 곱셈 규칙

곱셈 규칙은 조건부 확률의 정의식을 변형하여 두 사건이 동시에 발생할 확률을 구하는 방법입니다. 조건부 확률 공식 $P(A|B) = \frac{P(A \text{ and } B)}{P(B)}$의 양변에 $P(B)$를 곱하면 다음과 같은 일반 곱셈 규칙을 얻습니다.

$$
P(A \text{ and } B) = P(B) \times P(A|B)
$$

하지만 곱셈 규칙은 대칭적이어서 다음 형태도 성립합니다:
$$P(A \text{ and } B) = P(A) \times P(B|A)$$

카드를 임의로 섞고 맨 위에서 두 장을 연속으로 선택했을 때 두 장 모두 킹일 확률을 구하는 예시를 살펴봅시다. 첫 번째 카드가 킹일 확률은 $P(A) = \frac{4}{52}$입니다. 첫 번째 카드가 킹이라는 조건하에서 두 번째 카드도 킹일 조건부 확률은 $P(B|A) = \frac{3}{51}$입니다. 첫 번째 카드를 뽑았으므로 남은 카드는 51장이고, 그 중 킹은 3장이 남았기 때문입니다. 따라서 두 카드 모두 킹일 확률은 $P(A \text{ and } B) = \frac{4}{52} \times \frac{3}{51} = \frac{1}{221}$이 됩니다.

이 곱셈 규칙은 $P(A)$와 $P(B|A)$를 알거나 계산하기 쉬울 때 $P(A \text{ and } B)$를 구하는 데 매우 유용합니다.

### 3.2.5 독립

두 무작위 과정이 독립(independent)이라는 것은 한 사건의 결과가 다른 사건의 결과에 대해 아무런 정보를 제공하지 않는다는 의미입니다. 수학적으로 표현하면, 사건 A와 B가 독립일 때 다음이 성립합니다.

$$P(A|B) = P(A)$$

개념적으로 보면, B가 주어져도 A에 대해 아무것도 알려주지 않는다는 의미입니다. 동등하게 $P(B|A) = P(B)$를 확인함으로써도 독립성을 검증할 수 있습니다.

동전을 두 번 던질 때 첫 번째 던지기에서 앞면이 나왔다는 사실은 두 번째 던지기 결과에 대해 어떠한 정보도 제공하지 않습니다. 따라서 두 번의 동전 던지기 결과는 독립입니다. 반면에 카드 한 벌에서 복원 없이 카드를 두 장 뽑는 경우, 첫 번째 카드가 에이스라는 사실은 두 번째 카드가 에이스일 확률에 영향을 줍니다. 따라서 이 두 사건은 종속(dependent)입니다.

사건 A와 B가 독립일 때 곱셈 규칙은 단순화됩니다.

$$P(A \text{ and } B) = P(A) \times P(B)$$

이는 일반 곱셈 규칙 $P(A \text{ and } B) = P(A) \times P(B|A)$에서 $P(B|A)$가 $P(B)$로 축약된 형태입니다. 더 일반적으로, $A_1, \ldots, A_k$가 모두 독립이면 다음이 성립합니다.

$$P(A_1 \text{ and } \cdots \text{ and } A_k) = P(A_1) \times \cdots \times P(A_k)$$

### 3.2.6 베이즈 정리

베이즈 정리는 조건부 확률을 역전시키는 강력한 도구입니다. $P(B|A)$를 알고 있을 때 $P(A|B)$를 구하고자 하는 상황에서 사용됩니다. 베이즈 정리의 공식은 다음과 같습니다.

$$P(A|B) = \frac{P(A)P(B|A)}{P(A)P(B|A) + P(A^c)P(B|A^c)}$$

이 공식은 조건부 확률의 정의와 전체 확률 정리를 결합하여 유도됩니다. 먼저 $P(A|B) = \frac{P(A \text{ and } B)}{P(B)}$이고, 곱셈 규칙에 의해 분자는 $P(A)P(B|A)$가 됩니다. 분모인 $P(B)$는 $P(B \text{ and } A) + P(B \text{ and } A^c)$로 분해할 수 있으며, 각각에 곱셈 규칙을 적용하면 위의 형태가 됩니다.

베이즈 정리는 관찰 결과로부터 숨겨진 원인을 추론하는 데 매우 유용합니다. Alice가 Bob에게 "dot"과 "dash"로 코딩된 메시지를 보낼 때, 전송 과정에서 $\frac{1}{8}$ 확률로 신호가 바뀝니다. Bob이 "dot"을 수신했을 때 Alice가 실제로 "dot"을 보냈을 확률을 구하기 위해 베이즈 정리를 사용합니다.

더 일반적으로, 표본 공간의 분할 $A_1, A_2, \ldots, A_n$이 주어졌을 때 베이즈 규칙은 다음과 같이 확장됩니다.

$$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^{n}P(B|A_j)P(A_j)}$$

베이즈 정리를 언제 사용해야 할까요? $P(A|B)$를 직접 계산할 수 없지만 $P(B|A)$, $P(B|A^c)$, $P(A)$를 알고 있을 때 사용합니다. 만약 이들도 알 수 없다면 다른 방법을 찾아야 합니다.

### 3.2.7 전체 확률 정리

전체 확률 정리는 조건부 확률을 이용하여 어떤 사건의 확률을 계산하는 방법입니다. 표본 공간 $\Omega$의 분할 $A_1, \ldots, A_n$이 있고 모든 $A_i$에 대해 $P(A_i) > 0$일 때, 임의의 사건 B에 대해 다음이 성립합니다.

$$P(B) = P(A_1)P(B|A_1) + \cdots + P(A_n)P(B|A_n)$$

이는 사건 B를 여러 배타적인 경로로 분해하여 각 경로의 확률을 합산하는 개념입니다. 곱셈 규칙에 의해 $P(A_i \cap B) = P(A_i)P(B|A_i)$이므로, B는 모든 $A_i$와의 교집합들의 합집합으로 표현되며 이들은 서로 배반이므로 확률을 단순히 더할 수 있습니다.

전체 확률 정리는 복잡한 사건의 확률을 더 간단한 조건부 확률들로 분해할 때 유용하며, 특히 베이즈 정리의 분모를 계산하는 데 필수적으로 사용됩니다. 면접 성공 확률을 구할 때, 긴장하는 경우와 긴장하지 않는 경우로 나누어 각각의 조건부 확률과 사전 확률을 곱한 후 합산하는 방식으로 전체 확률 정리를 적용합니다.

---
## 3.3 확률(Probability) 변수 및 분포

### 3.3.1 확률 변수 (Random Variable, X)

확률 변수는 무작위 사건에 의존하는 양이나 대상을 수학적으로 형식화한 것입니다. 보다 정확하게 말하면, 확률 변수는 표본 공간 $\Omega$에서 측정 가능한 공간, 주로 실수로의 대응 또는 함수입니다. 즉, 확률 변수는 표본 공간에서 실수로 가는 함수입니다.

28명의 수강생이 수업을 이해하고 있는지 조사하는 상황을 생각해봅시다. 이해하고 있으면 1, 아니면 0으로 응답을 받으면 $2^{28}$개의 가능한 결과가 존재합니다. 하지만 실제로 관심있는 지표는 "28명의 수강생 중 몇 명이 수업을 이해하고 있는가"와 같은 요약된 값입니다. $X$를 수업을 잘 이해하고 있는 수강생의 숫자로 정의하면, $X$의 값의 범위는 ${0, 1, \ldots, 28}$이 되며 다루기가 훨씬 쉬워집니다.

확률 변수의 예시는 다양합니다. 동전을 던졌을 때 앞면인지 뒷면인지, 주사위를 굴렸을 때 나오는 숫자, 동전을 세 번 던졌을 때 앞면의 개수, 주사위 두 개를 굴렸을 때 두 수의 합, 주사위를 굴려서 6이 나올 때까지 필요한 횟수 등이 모두 확률 변수입니다.

### 3.3.2 확률 분포

확률 분포는 실험에서 발생 가능한 서로 다른 결과들의 확률을 제공하는 수학적 함수입니다. 확률 변수 $X$가 특정 값을 가질 확률 또는 특정 범위에 속할 확률을 나타내는 함수를 확률 분포라고 합니다.

확률 분포는 확률 변수가 어떤 값을 취하는지에 대한 전체적인 패턴을 보여줍니다. 예를 들어, 공정한 동전을 10번 던질 때 앞면이 몇 개 나올지, 로또를 몇 장 사야 1등에 당첨될지와 같은 질문에 답하기 위해서는 해당 확률 변수의 분포를 알아야 합니다.

### 3.3.3 이산 확률 변수

이산 확률 변수는 유한개 또는 최대한 셀 수 있는 무한개의 값을 가질 수 있는 확률 변수입니다. 예를 들어 베르누이 확률 변수는 ${0, 1}$의 값을 가질 수 있고, 이항 분포 $\text{Binomial}(n, p)$ 확률 변수는 ${0, 1, \ldots, n}$의 값을 가질 수 있으며, 기하 분포 $\text{Geometric}(p)$ 확률 변수는 임의의 양의 정수 값을 가질 수 있습니다.

이산 확률 변수의 확률 분포는 확률 질량 함수(Probability Mass Function, PMF)로 표현됩니다. PMF는 이산 확률 변수가 정확히 어떤 값과 같을 확률을 제공하는 함수입니다. $p_X(x) = P(X = x)$로 표기하며, 이는 확률 변수 $X$가 특정 값 $x$를 가질 확률을 의미합니다. PMF는 이산 확률 분포를 정의하는 주요 수단이며, 히스토그램으로 시각화할 수 있습니다. 또한 PMF를 사용하여 확률 변수의 기댓값과 분산을 계산할 수 있습니다.

예를 들어, 편향된 동전($P(H) = p$)을 10번 던질 때 앞면이 5개 나올 확률은 $P(X = 5) = \binom{10}{5}p^5(1-p)^5$로 계산됩니다. 이는 5개의 1을 포함하는 길이 10의 이진 수열을 생성할 확률이며, 독립성에 의해 유도됩니다.

### 3.3.4 연속 확률 변수

연속 확률 변수의 경우, 각 특정 값이 발생할 확률은 0이므로 PMF를 구성할 수 없습니다. 대신 확률 밀도 함수(Probability Density Function, PDF)라고 불리는 연속적이고 음이 아닌 함수 $f_X(x)$를 사용합니다.

PDF의 핵심은 확률 변수 $X$가 두 값 $x_1$과 $x_2$ 사이에 있을 확률이 PDF 아래의 면적, 즉 적분으로 계산된다는 것입니다.

$$P(x_1 \leq X \leq x_2) = \int_{x_1}^{x_2} f_X(x) dx$$

보다 일반적으로, 실수선의 임의의 부분집합 $B$에 대해 $P(X \in B) = \int_B f_X(x) dx$로 계산할 수 있습니다. 확률 변수 $X$가 작은 구간 $[x, x + \delta]$에 속할 확률은 $P(x \leq X \leq x + \delta) \approx f_X(x) \cdot \delta$로 근사할 수 있습니다. 단, $f_X(x)$ 자체는 $x$에서의 확률이 아니라 "단위 길이당 확률 질량"을 나타낸다는 점을 주의해야 합니다.

연속 균등 분포(continuous uniform distribution)는 연속 확률 변수의 대표적인 예입니다. 확률 변수 $X$가 구간 $[a, b]$에서 균등 분포를 따른다면, PDF는 해당 구간에서 상수 값을 가지며, 전체 면적이 1이 되도록 정규화됩니다.

### 3.3.5 누적 분포 함수 (CDF, $F_X(X)$)

누적 분포 함수(Cumulative Distribution Function, CDF)는 확률 변수 $X$가 특정 값 $x$ 이하일 확률을 나타내는 함수로, $F_X(x) = P(X \leq x)$로 정의됩니다. CDF는 이산 확률 변수와 연속 확률 변수 모두에 대해 정의할 수 있습니다.

이산 확률 변수의 경우, CDF는 다음과 같이 표현됩니다.

$$F_X(x) = P(X \leq x) = \sum_{x' \leq x} p_X(x')$$

이산 확률 변수의 CDF는 구간별 상수 함수의 형태를 가지며, 각 가능한 값에서 점프합니다.

연속 확률 변수의 경우, CDF는 다음과 같이 표현됩니다.

$$F_X(x) = P(X \leq x) = \int_{-\infty}^{x} f_X(x') dx'$$

연속 확률 변수의 CDF는 $x$에 대해 연속 함수입니다.

CDF는 여러 유용한 성질을 가집니다. CDF는 단조 비감소 함수입니다. 즉, $x \leq y$이면 $F_X(x) \leq F_X(y)$입니다. 또한 $x \to -\infty$일 때 $F_X(x) \to 0$이고, $x \to \infty$일 때 $F_X(x) \to 1$입니다.

실생활에서 $P(X \leq x)$를 구하는 상황은 매우 흔합니다. 버스가 오후 1시 30분 전에 올 확률, 수업 수강생을 임의로 선택했을 때 신발 사이즈가 260 이하일 확률, 주사위 두 개를 던졌을 때 두 수의 합이 8 이하일 확률 등이 모두 CDF를 사용하여 계산할 수 있습니다. $P(X \leq x)$를 알면 $P(X > x)$도 알 수 있으며, 이는 여사건 규칙에 의해 $1 - F_X(x)$로 계산됩니다.

---
## 3.4 기대값 및 분산 (Expected Value and Variance)

### 3.4.1 기대값/평균 (Expectation)

기대값 또는 평균은 확률 변수의 대표값으로, PMF의 무게중심으로 생각할 수 있습니다. 100명의 학생이 있고, 그 중 20명은 30점, 30명은 25점, 50명은 20점을 받았다면, 평균은 $\frac{30 \times 20 + 25 \times 30 + 20 \times 50}{100} = 30 \times 0.2 + 25 \times 0.3 + 20 \times 0.5$로 계산됩니다. 이는 각 점수에 그 점수를 받을 확률을 곱한 후 모두 합한 것입니다.

이산 확률 변수 $X$의 기댓값은 다음과 같이 정의됩니다.

$$E[X] = \sum_x x P(X = x)$$

베르누이 확률 변수의 기댓값을 예로 들어봅시다. $P(X = 1) = p$, $P(X = 0) = 1 - p$일 때, $E[X] = 1 \times p + 0 \times (1 - p) = p$입니다. 베르누이 확률 변수의 기댓값은 단순히 1이 나올 확률과 같습니다. 기댓값은 $\mu_X$와 같은 표기로도 나타냅니다.

연속 확률 변수의 경우, 기댓값은 합 대신 적분을 사용하여 계산됩니다.

$$E[X] = \int_{-\infty}^{\infty} x f_X(x) dx$$

연속 확률 변수의 기댓값도 마찬가지로 실험을 무한히 반복했을 때 평균적으로 얻을 것으로 예상되는 값이며, PDF의 무게중심으로 이해할 수 있습니다. 균등 분포 $[a, b]$를 따르는 확률 변수 $X$의 기댓값은 $E[X] = \frac{a + b}{2}$로, 구간의 중간점이 됩니다.

확률 변수의 함수 $g(X)$에 대한 기댓값도 계산할 수 있습니다. 이산 확률 변수의 경우 $E[g(X)] = \sum_x g(x) P(X = x)$이고, 연속 확률 변수의 경우 $E[g(X)] = \int_{-\infty}^{\infty} g(x) f_X(x) dx$입니다.

기댓값의 중요한 성질로 선형성이 있습니다. $Y = aX + b$일 때, $E[Y] = E[aX + b] = aE[X] + b$가 성립합니다. 이는 $E[aX + b] = \sum_x (ax + b) P(X = x) = a\sum_x x P(X = x) + b\sum_x P(X = x) = aE[X] + b$로 증명됩니다.

### 3.4.2 분산 (Variance, $Var(X)$)

분산은 자료의 흩어진 정도나 퍼진 정도를 측정하는 지표입니다. 100명의 수강생이 모두 같은 점수를 받았다면 분산은 0입니다. 수강생 점수에 높은 변동성이 있다면 수강생 점수가 평균 대비 서로 많이 다르다고 해석할 수 있습니다.

확률 변수 $X$가 있을 때, 분산은 다음과 같이 정의됩니다.

$$\text{var}(X) = E[(X - E[X])^2]$$

이는 확률 변수가 평균으로부터 떨어진 거리의 제곱에 대한 기댓값입니다. 분산을 계산하는 더 편리한 공식은 다음과 같습니다.

$$\text{var}(X) = E[X^2] - (E[X])^2$$

이 공식은 $\text{var}(X) = E[(X - E[X])^2] = \sum_x (x - E[X])^2 P(X = x)$를 전개하면 얻을 수 있습니다. $E[X]$는 특정 $x$ 값에 의존하지 않는 상수이므로, 이를 전개하면 $E[X^2] - (E[X])^2$가 됩니다.

베르누이 확률 변수의 분산을 계산해봅시다. $E[X] = p$이고, $E[X^2] = 1^2 \times p + 0^2 \times (1 - p) = p$입니다. 따라서 $\text{var}(X) = p - p^2 = p(1 - p)$입니다.

분산의 중요한 성질은 다음과 같습니다. $Y = X + b$일 때, 모든 데이터에 같은 값을 더했으므로 자료의 퍼진 정도는 같습니다. 따라서 $\text{var}(Y) = \text{var}(X)$입니다. 반면 $Y = aX$일 때, 모든 데이터에 같은 값을 곱하면 $a > 1$이면 퍼진 정도가 증가합니다. $\text{var}(aX) = a^2\text{var}(X)$가 성립합니다. 일반적으로 $\text{var}(aX + b) = a^2\text{var}(X)$입니다.

### 3.4.3 표준 편차 (Standard Deviation, $\sigma_X$)

$X$의 표준 편차는 분산의 제곱근으로 정의되며, $\sigma_X = \sqrt{\text{var}(X)}$로 표기합니다. 표준 편차는 분산과 달리 원래 데이터와 같은 단위를 가지므로 해석이 더 직관적입니다. 평균이 20이고 표준 편차가 5라고 하면, 대략 대부분의 학생 점수가 $[20 - 5, 20 + 5]$ 사이에 있다고 생각할 수 있습니다.

표준 편차는 분산보다 스케일이 같기 때문에 실제 응용에서 더 자주 사용됩니다. 분산은 원래 단위의 제곱 단위를 가지지만, 표준 편차는 원래 단위 그대로 유지되어 데이터의 퍼진 정도를 더 직관적으로 이해할 수 있게 해줍니다.

### 3.4.4 주요 분포의 평균/분산

주요 확률 분포들의 평균과 분산은 다음과 같습니다.

**정규 분포(Normal):** $X \sim N(\mu, \sigma^2)$일 때, $E[X] = \mu$이고 $\text{var}(X) = \sigma^2$입니다. 정규 분포는 파라미터 자체가 평균과 분산을 나타냅니다.

**[[베르누이 분포(Bernoulli)]]:** $X$가 베르누이 확률 변수이고 $P(X = 1) = p$일 때, $E[X] = p$이고 $\text{var}(X) = p(1 - p)$입니다.

**이항 분포(Binomial):** $X \sim \text{Bin}(n, p)$일 때, $E[X] = np$이고 $\text{var}(X) = np(1 - p)$입니다. 이항 분포는 독립적인 베르누이 시행의 합이므로, 평균과 분산이 개별 베르누이의 $n$배가 됩니다.

**푸아송 분포(Poisson):** $X \sim \text{Poisson}(\lambda)$일 때, $E[X] = \lambda$이고 $\text{var}(X) = \lambda$입니다. 흥미롭게도 푸아송 분포는 평균과 분산이 같습니다.

**기하 분포(Geometric):** $X \sim \text{Geometric}(p)$이고 $P(X = k) = (1 - p)^{k-1}p$일 때, $E[X] = \frac{1}{p}$이고 $\text{var}(X) = \frac{1 - p}{p^2}$입니다. 성공 확률이 $p$일 때 첫 성공까지 평균적으로 $\frac{1}{p}$번의 시행이 필요합니다.

**균등 분포(Uniform):** $X$가 $[a, b]$ 구간의 연속 균등 분포를 따를 때, $E[X] = \frac{a + b}{2}$이고 $\text{var}(X) = \frac{(b - a)^2}{12}$입니다.

이항 분포와 푸아송 분포는 모두 사건이 몇 번 발생하는지를 모델링하기 위해 사용되며, 각 사건은 독립을 가정합니다. 차이점은 이항 분포의 경우 정해진 시행 횟수에서 성공 횟수를 세는 반면, 푸아송 분포는 특정 시간 간격 동안 몇 번 이벤트가 일어나는지를 모델링합니다. $n$이 매우 크고 $p$가 매우 작을 때, 이항 분포는 $\lambda = np$인 푸아송 분포로 잘 근사됩니다.

---
## 3.5 다변수 확률 변수 (Multivariate Random Variables)

### 3.5.1 Joint PDF ($f_{X,Y}(x, y)$)

$X$와 $Y$가 두 개의 연속 확률 변수라고 가정합시다. $X \in \mathbb{R}$, $Y \in \mathbb{R}$일 때, $X$와 $Y$를 세트로 묶어 2차원 확률 분포로 표현할 수 있습니다. 즉, $(X, Y) \in \mathbb{R}^2$입니다.

어떤 연속 함수 $f_{X,Y}$가 있어서, $\mathbb{R}^2$의 모든 부분집합 $B$에 대해 $X$와 $Y$가 어떤 부분집합 $B$에 속할 확률을 다음과 같이 계산할 수 있으면, $X$와 $Y$가 결합 연속(jointly continuous)이라고 하고, $f_{X,Y}$를 $X$와 $Y$의 결합 확률 밀도 함수(joint PDF)라고 합니다.

$$P((X, Y) \in B) = \int \int_B f_{X,Y}(x, y) , dx , dy$$

결합 PDF $f_{X,Y}(x, y)$는 $(X, Y)$ 근처의 작은 영역에 대한 "단위 면적당 확률 질량(probability mass per unit area)"으로 생각할 수 있습니다. 중요한 점은 $f_{X,Y}(x, y)$ 자체는 확률이 아니라는 것입니다. 1차원 PDF처럼 밀도 함수일 뿐이며, 확률을 얻기 위해서는 영역에 대한 적분이 필요합니다.

$X$와 $Y$의 임의의 조합이 나올 확률은 분포를 알고 있다는 가정하에 계산 가능합니다. 예를 들어, 몸무게가 70kg 이하면서 키가 190cm 이상일 확률은 $P(-\infty \leq X \leq 70, 190 \leq Y \leq \infty) = \int_{-\infty}^{70} \int_{190}^{\infty} f_{X,Y}(x, y) , dy , dx$로 계산됩니다. 또는 키(cm)가 몸무게(kg)의 두 배 이상일 확률은 적절한 영역에 대한 이중 적분으로 표현할 수 있습니다.

구체적인 예시로 이변량 균등 분포를 살펴봅시다. Alice($X$)와 Bob($Y$)이 각각 0부터 10 사이에서 임의로 하나의 실수 값을 고른다고 가정합시다. 이때 확률 분포가 연속 균등 분포를 따른다면, 결합 PDF는 다음과 같습니다.

$$f_{X,Y}(x, y) = \begin{cases} 0.01 & \text{if } (x, y) \in [0, 10] \times [0, 10] \ 0 & \text{otherwise} \end{cases}$$

이는 10×10 정사각형 영역에서 균등하게 분포하며, 전체 면적에 대한 적분이 1이 되도록 정규화된 값입니다.

전체 확률 공간에 대한 적분은 다음과 같이 1이 되어야 합니다.

$$\int_{x=-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x, y) , dx , dy = 1$$

이는 $(X, Y)$가 전체 공간 어딘가에 반드시 존재한다는 것을 의미합니다.

### 3.5.2 주변 확률 (Marginal Probability)

결합 확률 분포로부터 개별 확률 변수의 분포를 구할 수 있으며, 이를 주변 확률(marginal probability) 또는 주변 분포(marginal distribution)라고 합니다. 주변화(marginalization)는 관심 없는 확률 변수를 제거하여 특정 확률 변수만의 분포를 얻는 과정입니다.

이산 확률 변수의 경우, $X$와 $Y$의 결합 PMF로부터 $X$의 주변 PMF를 구하려면 $Y$에 대해 합을 구하면 됩니다.

$$p_X(x) = \sum_y p_{X,Y}(x, y)$$

이는 $Y$의 모든 가능한 값에 대해 더하여 $Y$를 주변화한 것입니다.

연속 확률 변수의 경우, $X$와 $Y$의 결합 PDF로부터 $X$의 주변 PDF를 구하려면 $Y$에 대해 적분을 수행합니다.

$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) , dy$$

이는 $Y$의 모든 가능한 값에 대해 적분하여 $Y$를 주변화한 것입니다.

앞서 본 이변량 균등 분포 예시에서 $X$의 주변 PDF를 계산해봅시다.

$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) , dy = \int_{y=0}^{10} 0.01 , dy = 0.1 \quad \text{if } x \in [0, 10]$$

결과적으로 $f_X(x) = 0.1$ (for $x \in [0, 10]$)이 되며, 이는 $X \sim \text{Uniform}([0, 10])$임을 나타냅니다. 마찬가지로 $Y \sim \text{Uniform}([0, 10])$입니다.

주변 확률의 개념은 이전에 본 조건부 확률에서도 등장했습니다. 범주형 변수를 하나만 포함하고 있는 확률을 주변 확률이라고 하며, 결합 확률로부터 계산할 수 있습니다. 예를 들어 $P(A) = P(A, <40) + P(A, 40-49) + P(A, 50-59) + P(A, 60+) = \sum_{B_i} P(A, B_i)$와 같이 표현됩니다.

주변화의 예시로, Alice가 고른 숫자가 7보다 클 확률을 구한다면, 결합 분포에서 $X > 7$인 영역에 대해 $Y$를 모두 적분하면 됩니다. 이는 $Y$의 값에 관계없이 $X$만의 조건을 만족하는 확률을 구하는 것입니다.

주변화는 다변수 확률 변수를 단일 확률 변수로 축소하는 핵심적인 기법이며, 복잡한 결합 분포로부터 개별 변수의 특성을 파악하는 데 필수적입니다.