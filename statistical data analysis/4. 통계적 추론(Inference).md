# 4. 통계적 추론(Inference)

## Contents

- **4.1 통계적 추론의 기본: 확률 표본, 통계량, 중심 극한 정리 (Foundation: Samples, Statistics, and CLT)**
- **4.2 모수 추정 방법: 최대 우도 추정 및 신뢰 구간 (Methods of Parameter Estimation: MLE and CI)**
- **4.3 가설 검정의 기본 틀과 오류 (Hypothesis Testing Framework and Errors)**
- **4.4 T-분포와 다양한 T-검정의 활용 (T-Distribution and T-Test Applications)**
- **4.5 통계적 검정의 조건 확인 및 비모수적 대안 (Checking Assumptions and Non-parametric Alternatives)**

---

# 4.1 통계적 추론의 기본: 확률 표본, 통계량, 중심 극한 정리

통계적 추론은 관측된 표본 데이터를 바탕으로 모집단의 특성을 파악하는 과정입니다. 이를 위해서는 먼저 표본이 어떻게 수집되고, 표본으로부터 계산된 통계량이 무엇을 의미하는지, 그리고 표본 평균과 같은 통계량이 어떤 분포적 성질을 갖는지 이해해야 합니다. 이 절에서는 통계적 추론의 토대가 되는 확률 표본, 통계량, 그리고 중심 극한 정리의 개념을 다룹니다.

## 4.1.1 확률 표본 (Random Sample)의 개념

통계적 추론의 출발점은 **모집단으로부터 추출한 표본**입니다. 그러나 모든 표본이 통계적으로 유용한 것은 아닙니다. 표본이 모집단을 대표할 수 있으려면 무작위로 추출되어야 하며, **각 관측값은 서로 독립적**이어야 합니다.

### 4.1.1.1 독립적이고 동일하게 분포된 (i.i.d.) 확률 변수

확률 표본은 독립적이고 동일하게 분포된(independent and identically distributed, i.i.d.) 확률 변수들의 모음으로 정의됩니다. $X_1, X_2, \ldots, X_n$이 i.i.d.라는 것은 두 가지 조건을 만족한다는 의미입니다.

첫째, 모든 확률 변수가 동일한 분포를 따릅니다. 즉, 각 $X_i$는 같은 확률 분포 함수를 가지며, 따라서 같은 기대값 $\mu$와 분산 $\sigma^2$을 공유합니다. 이는 각 관측값이 동일한 모집단으로부터 추출되었음을 보장합니다.

둘째, 각 확률 변수는 서로 독립입니다. 즉, 한 관측값의 결과가 다른 관측값에 영향을 주지 않습니다. 수학적으로는 $X_i$와 $X_j$ $(i \neq j)$의 결합 분포가 각각의 주변 분포의 곱으로 표현됩니다. 이러한 독립성은 복원 추출이나 충분히 큰 모집단에서의 비복원 추출을 통해 근사적으로 달성됩니다.

### 4.1.1.2 확률 변수($X_i$)와 실현값($x_i$)의 구분

통계학에서는 확률 변수와 그것의 실현값을 명확히 구분합니다. 확률 변수 $X_i$는 표본 추출 전의 이론적 개념으로, 가능한 모든 값과 그 확률을 포함하는 추상적 대상입니다. 반면 실현값 $x_i$는 실제로 관측된 구체적인 숫자입니다.

예를 들어, 동전을 던지기 전의 결과는 확률 변수 $X$로 표현되며, 이는 앞면(1) 또는 뒷면(0)이 각각 0.5의 확률로 나타날 수 있습니다. 그러나 실제로 동전을 던진 후 관측된 결과 "앞면"은 실현값 $x = 1$입니다. 이러한 구분은 통계량의 성질을 논할 때 특히 중요합니다. 표본이 추출되기 전에는 표본 평균 $\bar{X}$도 확률 변수이지만, 관측 후에는 구체적인 값 $\bar{x}$가 됩니다.

## 4.1.2 통계량 (Statistics)의 정의와 종류

통계량은 표본 데이터로부터 계산되는 함수입니다. 정확히 말하면, 통계량은 확률 표본 $X_1, X_2, \ldots, X_n$의 함수 $T(X_1, X_2, \ldots, X_n)$으로 정의되며, 이 함수는 미지의 모수를 포함하지 않아야 합니다. 통계량 자체도 확률 변수이므로 고유한 분포, 기대값, 분산을 갖습니다.

### 4.1.2.1 표본 합, 표본 평균, 표본 분산

가장 기본적인 통계량들은 표본의 위치와 산포를 요약합니다.

**표본 합(Sample Sum)** 은 모든 관측값을 더한 값으로 $S_n = \sum_{i=1}^{n} X_i$입니다. 표본 합의 기대값은 $E[S_n] = n\mu$이고, 분산은 독립성 가정 하에서 $\text{Var}(S_n) = n\sigma^2$입니다.

**표본 평균(Sample Mean)** 은 표본의 중심 위치를 나타내는 통계량으로 $\bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_i$로 정의됩니다. 표본 평균은 모집단 평균 $\mu$의 불편 추정량(unbiased estimator)입니다. 즉, $E[\bar{X}] = \mu$입니다. 표본 평균의 분산은 $\text{Var}(\bar{X}) = \frac{\sigma^2}{n}$으로, 표본 크기가 증가할수록 분산이 감소합니다.

**표본 분산(Sample Variance)** 은 데이터의 산포를 측정하는 통계량으로 $S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$로 정의됩니다. 분모에 $n$ 대신 $n-1$을 사용하는 이유는 불편성을 보장하기 위함입니다. 실제로 $E[S^2] = \sigma^2$가 성립합니다. $n-1$은 자유도(degrees of freedom)라고 하며, 이는 $\bar{X}$를 계산하는 데 하나의 제약 조건이 사용되었음을 반영합니다.

## 4.1.3 표본 분포와 중심 극한 정리 (CLT)

통계량은 확률 변수이므로 자체적인 확률 분포를 갖습니다. 이를 표본 분포(sampling distribution)라고 합니다. 표본 분포는 동일한 크기의 표본을 반복적으로 추출할 때 통계량이 어떻게 변할지를 보여줍니다.

### 4.1.3.1 표본 평균의 기대값 및 표준 오차 (Standard Error)

표본 평균 $\bar{X}$의 표본 분포는 통계적 추론에서 핵심적인 역할을 합니다. 앞서 언급했듯이 $E[\bar{X}] = \mu$이고 $\text{Var}(\bar{X}) = \frac{\sigma^2}{n}$입니다.

표준 오차(Standard Error, SE)는 표본 평균의 표준 편차를 의미하며 $SE(\bar{X}) = \frac{\sigma}{\sqrt{n}}$로 정의됩니다. 표준 오차는 표본 평균이 모집단 평균으로부터 얼마나 떨어져 있을 가능성이 있는지를 나타냅니다. 표본 크기 $n$이 증가하면 표준 오차는 감소하며, 이는 큰 표본일수록 표본 평균이 모집단 평균에 가까워질 가능성이 높다는 것을 의미합니다.

실제 분석에서는 모집단 표준편차 $\sigma$를 알 수 없으므로, 표본 표준편차 $S$를 사용하여 추정 표준 오차 $\hat{SE}(\bar{X}) = \frac{S}{\sqrt{n}}$를 계산합니다.

### 4.1.3.2 중심 극한 정리의 조건과 적용

중심 극한 정리(Central Limit Theorem, CLT)는 통계학에서 가장 중요한 이론 중 하나입니다. 이 정리는 모집단의 분포가 무엇이든 관계없이, 표본 크기가 충분히 크면 표본 평균의 분포가 정규 분포에 근사한다는 것을 보장합니다.

구체적으로, $X_1, X_2, \ldots, X_n$이 평균 $\mu$와 분산 $\sigma^2$를 가진 i.i.d. 확률 변수일 때, 표본 크기 $n$이 충분히 크면 표준화된 표본 평균 $Z_n = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}$의 분포는 표준 정규 분포 $N(0, 1)$에 근사합니다. 다시 말해, $\bar{X}$는 근사적으로 $N(\mu, \sigma^2/n)$을 따릅니다.

중심 극한 정리가 적용되기 위한 조건은 명확합니다. 첫째, 관측값들이 독립적이어야 합니다. 둘째, 동일한 분포를 따라야 합니다. 셋째, 모집단의 평균과 분산이 유한해야 합니다. 이 조건들이 만족되면 모집단의 분포가 정규 분포가 아니더라도, 심지어 극단적으로 치우친 분포라 하더라도, 표본 평균은 정규 분포에 가까워집니다.

"충분히 큰" 표본 크기의 기준은 모집단 분포의 형태에 따라 다릅니다. 모집단이 정규 분포에 가까우면 $n = 30$만으로도 충분할 수 있지만, 극단적으로 치우쳤거나 두꺼운 꼬리를 가진 분포에서는 더 큰 표본이 필요할 수 있습니다. 실무적으로는 $n \geq 30$을 기준으로 삼는 경우가 많습니다.

중심 극한 정리의 중요성은 이것이 정규 분포에 기반한 통계적 방법론을 광범위하게 사용할 수 있게 해준다는 점입니다. 모집단의 실제 분포를 알지 못하더라도, 큰 표본에서는 표본 평균이 정규 분포를 따른다고 가정하고 신뢰 구간을 구성하거나 가설 검정을 수행할 수 있습니다. 이는 통계적 추론의 실용적 기반을 제공하는 핵심 원리입니다.

---

# 4.2 [[모수(parameter)]] 추정 방법: 최대 우도 추정 및 신뢰 구간

통계적 추론의 핵심 목표 중 하나는 모집단의 모수를 추정하는 것입니다. **모수는 모집단의 특성을 나타내는 고정된 값**이지만, 일반적으로 우리는 이를 직접 알 수 없기 때문에 표본 데이터를 사용하여 추정해야 합니다. 이 절에서는 모수를 추정하는 두 가지 중요한 접근 방법인 최대 우도 추정과 신뢰 구간 구성 방법을 다룹니다.

## 4.2.1 추정의 기본 요소

모수 추정을 논의하기 전에 세 가지 핵심 개념을 명확히 구분해야 합니다.

### 4.2.1.1 추정량(Estimator), 추정값(Estimate), 추정 대상(Estimand)

**추정 대상(Estimand)** 은 우리가 알고자 하는 모집단의 모수입니다. 예를 들어, 모집단 평균 $\mu$, 모집단 분산 $\sigma^2$, 또는 회귀 계수 $\beta$ 등이 추정 대상에 해당합니다. 추정 대상은 고정된 값이지만 우리에게는 미지의 값입니다.

**추정량(Estimator)** 은 표본 데이터로부터 추정 대상을 추정하기 위해 사용하는 통계량입니다. 추정량은 확률 변수의 함수이므로 그 자체도 확률 변수입니다. 예를 들어, 모집단 평균 $\mu$의 추정량으로 표본 평균 $\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i$를 사용합니다. 추정량은 대문자로 표기하며, 관측되기 전의 이론적 개념입니다.

**추정값(Estimate)** 은 실제 표본 데이터가 관측된 후 추정량에 구체적인 숫자를 대입하여 얻은 값입니다. 예를 들어, 특정 표본에서 계산된 표본 평균 $\bar{x} = 5.2$가 추정값입니다. 추정값은 소문자로 표기하며, 하나의 실수입니다.

이 세 개념의 관계를 정리하면, 우리는 추정 대상(모수)을 알기 위해 추정량(통계량)을 설계하고, 실제 데이터가 주어지면 추정량을 통해 추정값(숫자)을 계산합니다.

## 4.2.2 최대 우도 추정 (Maximum Likelihood Estimation, MLE)

최대 우도 추정은 모수를 추정하는 가장 널리 사용되는 방법 중 하나입니다. 이 방법의 핵심 아이디어는 관측된 데이터가 나타날 가능성을 최대화하는 모수 값을 선택하는 것입니다.

### 4.2.2.1 우도 함수 ([[Likelihood Function]])의 정의

우도 함수는 주어진 데이터가 특정 모수 값 하에서 얼마나 그럴듯한지를 나타내는 함수입니다. 확률 밀도 함수 또는 확률 질량 함수 $f(x; \theta)$를 가진 모집단에서 i.i.d. 표본 $x_1, x_2, \ldots, x_n$이 관측되었을 때, 우도 함수 $L(\theta)$는 다음과 같이 정의됩니다.

$$L(\theta) = \prod_{i=1}^{n} f(x_i; \theta)$$

이 식에서 중요한 점은 관점의 전환입니다. 확률 함수 $f(x; \theta)$는 모수 $\theta$가 고정되고 $x$가 변하는 함수로 해석되지만, 우도 함수 $L(\theta)$는 관측값 $x_1, \ldots, x_n$이 고정되고 $\theta$가 변하는 함수로 해석됩니다.

예를 들어, 정규 분포 $N(\mu, \sigma^2)$로부터 표본을 추출했다면, 우도 함수는 다음과 같습니다.

$$L(\mu, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)$$

최대 우도 추정량(Maximum Likelihood Estimator, MLE) $\hat{\theta}_{MLE}$는 우도 함수를 최대화하는 모수 값입니다. 즉, $\hat{\theta}_{MLE} = \arg\max_{\theta} L(\theta)$입니다.

### 4.2.2.2 로그 우도 사용 이유 및 최적화

실제 계산에서는 우도 함수 대신 로그 우도 함수(log-likelihood function)를 사용합니다. 로그 우도 함수는 $\ell(\theta) = \log L(\theta)$로 정의되며, 여러 실용적 장점을 제공합니다.

첫째, 로그 함수는 단조 증가 함수이므로 $L(\theta)$를 최대화하는 값과 $\ell(\theta)$를 최대화하는 값이 동일합니다. 따라서 최적화 문제의 해는 변하지 않습니다.

둘째, 곱셈을 덧셈으로 변환하여 계산을 단순화합니다. 우도 함수는 각 관측값의 확률 밀도를 곱한 형태인데, 로그를 취하면 $\ell(\theta) = \sum_{i=1}^{n} \log f(x_i; \theta)$처럼 합의 형태가 됩니다. 이는 수치적으로 더 안정적이며, 미분 계산도 간단해집니다.

셋째, 수치적 안정성이 향상됩니다. 많은 관측값에 대해 작은 확률들을 곱하면 결과가 매우 작아져 컴퓨터의 부동소수점 연산에서 언더플로우(underflow) 문제가 발생할 수 있습니다. 로그를 취하면 이러한 문제를 피할 수 있습니다.

최대 우도 추정량을 구하는 과정은 다음과 같습니다. 먼저 로그 우도 함수 $\ell(\theta)$를 모수 $\theta$에 대해 미분합니다. 그 다음 도함수를 0으로 놓고 방정식을 풀어 임계점을 찾습니다. 이를 스코어 방정식(score equation)이라고 하며, $\frac{\partial \ell(\theta)}{\partial \theta} = 0$로 표현됩니다. 마지막으로 이차 도함수를 확인하여 찾은 임계점이 실제로 최댓값인지 검증합니다.

예를 들어, 정규 분포 $N(\mu, \sigma^2)$의 경우 로그 우도 함수를 $\mu$에 대해 미분하고 0으로 놓으면 $\hat{\mu}_{MLE} = \bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$를 얻습니다. 이는 표본 평균이 모집단 평균의 최대 우도 추정량임을 보여줍니다.

## 4.2.3 신뢰 구간 (Confidence Interval, CI)을 이용한 추정

점 추정은 모수의 단일 값을 제시하지만, 추정의 불확실성을 표현하지 못합니다. 신뢰 구간은 모수가 포함될 것으로 기대되는 값들의 범위를 제공하여 추정의 불확실성을 정량화합니다.

### 4.2.3.1 신뢰 구간의 계산 원리 ($\bar{X} \pm Z \cdot SE$)

신뢰 구간은 특정 신뢰 수준(confidence level) 하에서 모수가 포함될 가능성이 높은 구간을 의미합니다. 예를 들어, 95% 신뢰 구간은 동일한 방법으로 구간을 반복적으로 구성할 때, 약 95%의 구간이 실제 모수를 포함할 것이라는 의미입니다.

모집단 평균 $\mu$에 대한 신뢰 구간을 구성하는 기본 원리는 중심 극한 정리에 기반합니다. 표본 크기가 충분히 크면 표본 평균 $\bar{X}$는 근사적으로 $N(\mu, \sigma^2/n)$을 따릅니다. 이를 표준화하면 $Z = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}$는 표준 정규 분포 $N(0, 1)$을 따릅니다.

$100(1-\alpha)$ 신뢰 구간을 구성하기 위해, 표준 정규 분포에서 $P(-z_{\alpha/2} < Z < z_{\alpha/2}) = 1-\alpha$를 만족하는 임계값 $z_{\alpha/2}$를 찾습니다. 예를 들어, 95% 신뢰 구간의 경우 $\alpha = 0.05$이고 $z_{0.025} = 1.96$입니다.

이를 $\mu$에 대해 정리하면 다음과 같은 신뢰 구간을 얻습니다.

$$\bar{X} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}} < \mu < \bar{X} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}$$

이는 일반적으로 $\bar{X} \pm z_{\alpha/2} \cdot SE$로 표현되며, 여기서 $SE = \frac{\sigma}{\sqrt{n}}$는 표본 평균의 표준 오차입니다.

신뢰 구간의 해석에서 주의할 점은, 이것이 확률적 진술이 아니라는 것입니다. 특정 표본으로부터 계산된 신뢰 구간 $[a, b]$에 대해 "$\mu$가 $[a, b]$에 있을 확률이 95%이다"라고 말할 수 없습니다. 모수 $\mu$는 고정된 값이므로 확률 변수가 아닙니다. 올바른 해석은 "이러한 방법으로 구간을 반복적으로 구성하면, 장기적으로 약 95%의 구간이 실제 $\mu$를 포함할 것이다"입니다.

### 4.2.3.2 모 표준 편차($\sigma$) 미지 시 표본 표준 편차($s$) 대체 문제

실제 상황에서는 모집단 표준편차 $\sigma$를 알지 못하는 경우가 대부분입니다. 이 경우 표본 표준편차 $s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$를 사용하여 $\sigma$를 대체해야 합니다.

그러나 단순히 $\sigma$를 $s$로 대체하면 문제가 발생합니다. $\frac{\bar{X} - \mu}{s/\sqrt{n}}$는 더 이상 정확히 표준 정규 분포를 따르지 않습니다. 왜냐하면 분모에 있는 $s$도 확률 변수이며, $\bar{X}$와 통계적으로 연관되어 있기 때문입니다. 이는 추가적인 변동성을 도입하며, 특히 표본 크기가 작을 때 더욱 두드러집니다.

이러한 문제를 해결하기 위해 t-분포를 사용합니다. 정규 분포로부터의 표본에서 $T = \frac{\bar{X} - \mu}{s/\sqrt{n}}$는 자유도 $n-1$인 t-분포를 따릅니다. t-분포는 표준 정규 분포보다 꼬리가 두껍기 때문에, $\sigma$를 $s$로 대체함으로써 생기는 추가 불확실성을 반영합니다.

> T-분포는 자유도라는 모수를 가지며, 평균이 0이고 종 모양이지만 정규 분포보다 꼬리가 두꺼운 형태

따라서 모 표준편차를 모를 때의 신뢰 구간은 다음과 같이 구성됩니다.

$$\bar{x} \pm t_{\alpha/2, n-1} \cdot \frac{s}{\sqrt{n}}$$

여기서 $t_{\alpha/2, n-1}$은 자유도 $n-1$인 t-분포의 상위 $\alpha/2$ 백분위수입니다. 표본 크기가 충분히 크면(일반적으로 $n \geq 30$) t-분포는 표준 정규 분포에 근사하므로, $t_{\alpha/2, n-1} \approx z_{\alpha/2}$가 됩니다. 그러나 작은 표본에서는 t-분포를 사용하는 것이 필수적이며, 이를 통해 더 넓고 보수적인 신뢰 구간을 얻게 됩니다.

---

# 4.3 가설 검정의 기본 틀과 오류

가설 검정은 표본 데이터를 바탕으로 모집단에 대한 주장을 평가하는 통계적 절차입니다. 신뢰 구간이 모수의 값을 추정하는 데 초점을 맞춘다면, 가설 검정은 모수에 대한 특정 주장이 타당한지를 판단하는 데 중점을 둡니다. 이 절에서는 가설 검정의 기본 구조와 검정 과정에서 발생할 수 있는 오류의 종류를 다룹니다.

## 4.3.1 귀무 가설 ($H_0$) 및 대립 가설 ($H_A$)의 설정

가설 검정은 두 개의 상호 배타적인 가설을 설정하는 것에서 시작됩니다. 이 두 가설은 모집단의 모수에 대한 서로 다른 주장을 나타냅니다.

**귀무 가설(Null Hypothesis)** $H_0$는 일반적으로 "변화가 없다", "차이가 없다", "효과가 없다"는 현상 유지 또는 회의적 입장을 나타냅니다. 귀무 가설은 검정의 출발점이며, 반증되기 전까지는 참으로 가정되는 주장입니다. 예를 들어, 신약의 효과를 검증하는 경우 귀무 가설은 "신약과 기존 약의 평균 효과가 같다"가 될 수 있습니다.

**대립 가설(Alternative Hypothesis)** $H_A$ 또는 $H_1$은 연구자가 실제로 입증하고자 하는 주장입니다. 대립 가설은 귀무 가설과 반대되는 입장으로, "변화가 있다", "차이가 있다", "효과가 있다"는 내용을 담습니다. 같은 예시에서 대립 가설은 "신약과 기존 약의 평균 효과가 다르다"가 됩니다.

대립 가설의 형태에 따라 검정은 세 가지 유형으로 구분됩니다. **양측 검정(two-sided test)** 은 모수가 특정 값과 다르다는 것을 검증하며, $H_A: \mu \neq \mu_0$ 형태입니다. **단측 검정(one-sided test)** 은 방향성을 가지며, 우측 검정은 $H_A: \mu > \mu_0$, 좌측 검정은 $H_A: \mu < \mu_0$의 형태를 갖습니다. 단측 검정은 특정 방향의 차이에만 관심이 있을 때 사용됩니다.

### 4.3.1.1 가설 설정 시 모집단 모수 사용의 중요성

가설은 반드시 모집단의 모수에 대한 진술이어야 합니다. 이는 통계적 추론이 표본을 넘어 모집단에 대한 결론을 도출하는 것을 목표로 하기 때문입니다.

예를 들어, "$H_0: \mu = 100$"은 모집단 평균에 대한 올바른 가설입니다. 반면 "$H_0: \bar{x} = 100$"처럼 표본 통계량에 대한 진술은 가설로 적절하지 않습니다. 표본 평균은 관측 가능한 값이며, 이미 계산된 후에는 더 이상 불확실한 대상이 아니기 때문입니다.

이러한 구분은 검정의 논리적 구조를 명확히 합니다. 우리는 표본 데이터로부터 계산된 통계량을 사용하여 모집단 모수에 대한 가설을 평가합니다. 만약 표본 통계량 자체가 가설의 대상이 된다면, 검정의 목적인 "표본으로부터 모집단으로의 추론"이 성립하지 않습니다.

또한 가설은 구체적이고 검증 가능해야 합니다. "$H_0: \mu = 100$"은 명확한 수치를 제시하지만, "$H_0:$ 평균이 크다"는 모호하여 검정이 불가능합니다. 모수에 대한 정확한 수학적 표현이 가설 검정의 전제 조건입니다.

## 4.3.2 검정 통계량 (Test Statistic)과 P-값 (P-value)

가설 검정의 핵심은 표본 데이터가 귀무 가설과 얼마나 일치하는지를 정량적으로 평가하는 것입니다. 이를 위해 검정 통계량과 P-값이라는 도구를 사용합니다.

**검정 통계량(Test Statistic)** 은 표본 데이터로부터 계산되며, 귀무 가설 하에서 알려진 분포를 따르는 통계량입니다. 예를 들어, 모집단 평균에 대한 검정에서는 Z-통계량 $Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}$ 또는 T-통계량 $T = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}$를 사용합니다. 여기서 $\mu_0$는 귀무 가설에서 주장하는 모수 값입니다.

검정 통계량은 표본이 귀무 가설로부터 얼마나 멀리 떨어져 있는지를 표준화된 척도로 측정합니다. 값이 0에 가까우면 표본이 귀무 가설과 일치함을 의미하고, 절댓값이 크면 표본이 귀무 가설과 크게 다름을 의미합니다.

### 4.3.2.1 P-값의 정의와 $H_0$에 대한 증거 강도

**P-값(P-value)** 은 귀무 가설이 참이라고 가정할 때, 관측된 데이터만큼 또는 그보다 더 극단적인 결과가 나타날 확률입니다. P-값은 귀무 가설에 반하는 증거의 강도를 나타내는 지표로 해석됩니다.

수학적으로 양측 검정의 경우, P-값은 $P = P(|T| \geq |t_{obs}| \mid H_0)$로 정의됩니다. 여기서 $t_{obs}$는 실제 표본에서 계산된 검정 통계량의 값입니다. 단측 검정의 경우 한쪽 꼬리의 확률만 고려합니다.

P-값의 해석은 다음과 같은 원리에 기반합니다. P-값이 작다는 것은 귀무 가설이 참일 때 관측된 데이터가 나타날 가능성이 매우 낮다는 의미입니다. 따라서 귀무 가설이 실제로 참이 아닐 가능성이 높다고 판단할 수 있습니다. 반대로 P-값이 크다면 관측된 데이터가 귀무 가설과 충분히 일치한다고 볼 수 있습니다.

일반적으로 P-값이 0.01보다 작으면 매우 강한 증거, 0.01에서 0.05 사이면 강한 증거, 0.05에서 0.10 사이면 약한 증거로 간주합니다. 그러나 P-값은 연속적인 척도이므로, 단순히 임계값을 기준으로 이분법적으로 판단하기보다는 증거의 강도를 나타내는 지표로 이해하는 것이 바람직합니다.

P-값에 대한 흔한 오해 중 하나는 "P-값이 귀무 가설이 참일 확률"이라고 생각하는 것입니다. 이는 잘못된 해석입니다. 귀무 가설은 참이거나 거짓인 고정된 명제이지 확률 변수가 아닙니다. P-값은 귀무 가설이 참이라는 조건 하에서 계산된 조건부 확률이며, 귀무 가설 자체의 확률이 아닙니다.

## 4.3.3 유의 수준 ($\alpha$)과 오류의 종류

가설 검정은 불완전한 정보(표본)를 바탕으로 판단을 내리기 때문에, 잘못된 결론에 도달할 가능성이 항상 존재합니다. 이러한 오류는 두 가지 유형으로 분류됩니다.

### 4.3.3.1 1종 오류 (Type 1 Error)와 유의 수준의 관계

**1종 오류(Type I Error)** 는 실제로는 귀무 가설이 참인데 이를 기각하는 오류입니다. 즉, "차이가 없는데 있다고 판단"하거나, "효과가 없는데 있다고 판단"하는 잘못된 양성(false positive)입니다. 이는 실제로 무죄인 사람을 유죄로 판결하는 것에 비유할 수 있습니다.

1종 오류가 발생할 확률을 $\alpha$로 표시하며, 이를 **유의 수준(significance level)** 이라고 합니다. 유의 수준은 연구자가 사전에 설정하는 값으로, 일반적으로 $\alpha = 0.05$ 또는 $\alpha = 0.01$을 사용합니다.

검정의 의사 결정 규칙은 P-값과 유의 수준을 비교하여 결정됩니다. P-값이 $\alpha$보다 작으면 귀무 가설을 기각하고, P-값이 $\alpha$보다 크거나 같으면 귀무 가설을 기각하지 못합니다. 이 규칙을 따를 때, 귀무 가설이 참인 상황에서 기각될 확률이 정확히 $\alpha$가 됩니다.

유의 수준의 선택은 1종 오류를 얼마나 허용할 것인가에 대한 연구자의 판단을 반영합니다. $\alpha = 0.05$는 귀무 가설이 참일 때 100번 중 5번은 잘못 기각할 수 있다는 것을 의미합니다. 더 엄격한 기준을 원한다면 $\alpha = 0.01$을 사용하여 1종 오류의 가능성을 낮출 수 있습니다.

그러나 $\alpha$를 너무 작게 설정하면 실제로 효과가 있음에도 이를 탐지하지 못할 위험이 커집니다. 이것이 바로 2종 오류입니다.

### 4.3.3.2 2종 오류 (Type 2 Error)의 개념 및 중요성

**2종 오류(Type II Error)** 는 실제로는 대립 가설이 참인데 귀무 가설을 기각하지 못하는 오류입니다. 즉, "차이가 있는데 없다고 판단"하거나, "효과가 있는데 없다고 판단"하는 잘못된 음성(false negative)입니다. 이는 실제로 유죄인 사람을 무죄로 판결하는 것에 비유할 수 있습니다.

2종 오류가 발생할 확률을 $\beta$로 표시합니다. $1 - \beta$를 **검정력(power)** 이라고 하며, 이는 대립 가설이 참일 때 이를 올바르게 탐지할 확률을 의미합니다. 높은 검정력은 실제 효과를 놓치지 않고 발견할 수 있는 능력을 나타내므로, 좋은 검정의 중요한 특성입니다.

2종 오류의 확률은 여러 요인에 의해 영향을 받습니다. 첫째, 표본 크기가 클수록 $\beta$는 감소합니다. 큰 표본은 더 정확한 추정을 가능하게 하므로, 작은 차이도 탐지할 수 있습니다. 둘째, 실제 효과 크기가 클수록 $\beta$는 감소합니다. 큰 차이는 작은 표본에서도 쉽게 발견됩니다. 셋째, 유의 수준 $\alpha$를 크게 설정할수록 $\beta$는 감소합니다. 그러나 이는 1종 오류의 증가를 동반합니다.

실제 연구 설계에서는 1종 오류와 2종 오류 사이의 균형을 고려해야 합니다. 일반적으로 1종 오류를 더 심각하게 보는 경향이 있어 $\alpha$를 먼저 고정하고, 적절한 표본 크기를 선택하여 충분한 검정력(예: $1 - \beta = 0.80$ 또는 0.90)을 확보하는 방식을 취합니다.

두 오류의 관계를 정리하면, $\alpha$를 줄이면 $\beta$가 증가하고, $\beta$를 줄이면 $\alpha$가 증가하는 상충 관계가 있습니다. 이러한 상충 관계를 완화하는 가장 효과적인 방법은 표본 크기를 증가시키는 것입니다. 충분히 큰 표본은 두 오류를 동시에 낮출 수 있게 합니다.

---

# 4.4 T-분포와 다양한 T-검정의 활용

실제 데이터 분석에서는 모집단의 표준편차를 알지 못하는 경우가 대부분입니다. 이러한 상황에서 표본 표준편차를 사용하면 정규 분포가 아닌 t-분포를 따르게 되며, 이에 따라 t-검정이라는 별도의 검정 방법이 필요합니다. 이 절에서는 t-분포의 특성과 다양한 상황에 적용되는 t-검정의 종류를 다룹니다.

## 4.4.1 T-분포 (Student's t-distribution)의 도입

t-분포는 20세기 초 William Sealy Gosset이 "Student"라는 필명으로 발표하여 Student's t-distribution이라고도 불립니다. 이 분포는 작은 표본에서 모집단 표준편차를 모를 때 표본 평균의 분포를 정확하게 기술하기 위해 개발되었습니다.

### 4.4.1.1 t-통계량의 정의와 자유도 (Degrees of Freedom)

t-통계량은 표본 평균을 표준화한 값으로, 모집단 표준편차 $\sigma$ 대신 표본 표준편차 $s$를 사용하여 계산됩니다. 모집단 평균 $\mu$에 대한 검정에서 t-통계량은 다음과 같이 정의됩니다.

$$T = \frac{\bar{X} - \mu}{s/\sqrt{n}}$$

이 통계량은 정규 분포를 따르는 모집단으로부터 추출된 표본에서 자유도 $df = n - 1$인 t-분포를 따릅니다.

**자유도(Degrees of Freedom)** 는 t-분포의 형태를 결정하는 핵심 모수입니다. 자유도는 통계량을 계산할 때 자유롭게 변할 수 있는 독립적인 정보의 개수를 의미합니다. 단일 표본의 경우 자유도가 $n - 1$인 이유는 표본 평균 $\bar{X}$를 계산하는 데 하나의 제약 조건이 사용되기 때문입니다. $n$개의 관측값이 있을 때, $n - 1$개의 값이 주어지면 나머지 하나의 값은 자동으로 결정됩니다.

예를 들어, 세 개의 관측값 $x_1, x_2, x_3$가 있고 평균이 10이라면, $x_1 = 8$, $x_2 = 11$일 때 $x_3$는 반드시 11이어야 합니다. 따라서 실제로 자유롭게 변할 수 있는 값은 두 개뿐이며, 자유도는 $3 - 1 = 2$가 됩니다.

### 4.4.1.2 T-분포의 형태적 특징 및 정규 분포와의 비교

t-분포는 정규 분포와 비슷한 종 모양을 가지며 평균 0을 중심으로 대칭입니다. 그러나 몇 가지 중요한 차이점이 있습니다.

첫째, t-분포는 정규 분포보다 꼬리가 두껍습니다. 이는 **극단적인 값이 나타날 확률이 정규 분포보다 높다**는 의미입니다. 꼬리가 두꺼운 이유는 $s$가 확률 변수이기 때문에 추가적인 변동성이 도입되기 때문입니다. 이러한 특성은 표본 표준편차로 모집단 표준편차를 추정할 때의 불확실성을 반영합니다.

둘째, t-분포의 형태는 자유도에 의존합니다. 자유도가 작을수록 꼬리가 더 두껍고 분산이 더 큽니다. 예를 들어, 자유도가 1인 t-분포는 매우 두꺼운 꼬리를 가지며, 심지어 분산이 무한대입니다. 자유도가 증가할수록 t-분포는 점점 정규 분포에 근사하며, 일반적으로 자유도가 30 이상이면 t-분포와 표준 정규 분포의 차이는 실용적으로 무시할 수 있을 정도로 작아집니다.

셋째, 작은 표본에서는 t-분포를 사용하는 것이 필수적입니다. $n$이 작을 때 정규 분포의 임계값을 사용하면 신뢰 구간이 너무 좁아지거나 가설 검정에서 1종 오류율이 명목 수준보다 높아질 수 있습니다. t-분포는 이러한 문제를 방지하여 더 보수적이고 정확한 추론을 가능하게 합니다.

## 4.4.2 단일 표본 T-검정 (One-sample t-Test)

단일 표본 t-검정은 하나의 표본 평균을 특정한 기준값과 비교하는 가설 검정입니다. 이는 모집단 평균이 특정 값 $\mu_0$와 같은지를 검정하는 데 사용됩니다.

가설은 다음과 같이 설정됩니다. 귀무 가설은 $H_0: \mu = \mu_0$이고, 대립 가설은 양측 검정의 경우 $H_A: \mu \neq \mu_0$, 단측 검정의 경우 $H_A: \mu > \mu_0$ 또는 $H_A: \mu < \mu_0$입니다.

검정 통계량은 다음과 같이 계산됩니다.

$$t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}$$

이 통계량은 귀무 가설이 참일 때 자유도 $n - 1$인 t-분포를 따릅니다. P-값은 t-분포에서 계산된 검정 통계량만큼 또는 그보다 극단적인 값이 나타날 확률입니다.

### 4.4.2.1 Z-검정과의 계산 통계량 차이

단일 표본 t-검정과 z-검정은 형태상 매우 유사하지만, 핵심적인 차이가 있습니다.

**계산 통계량의 차이**는 분모에 있습니다. z-검정은 $z = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}}$로 모집단 표준편차 $\sigma$를 사용하는 반면, t-검정은 $t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}$로 표본 표준편차 $s$를 사용합니다. 이 차이가 근본적으로 다른 분포를 만듭니다.

**참조 분포의 차이**도 중요합니다. z-검정 통계량은 표준 정규 분포 $N(0, 1)$을 따르는 반면, t-검정 통계량은 자유도 $n - 1$인 t-분포를 따릅니다. 따라서 임계값과 P-값도 서로 다른 분포 표를 참조하여 구합니다.

**적용 조건의 차이**는 실무적으로 가장 중요합니다. z-검정은 모집단 표준편차를 알고 있거나 표본 크기가 매우 클 때 사용합니다. 반면 t-검정은 모집단 표준편차를 모르는 경우에 사용하며, 특히 작은 표본에서 필수적입니다.

예를 들어, 표본 크기 $n = 10$이고 유의 수준 $\alpha = 0.05$인 양측 검정의 경우, 정규 분포의 임계값은 $\pm 1.96$이지만 자유도 9인 t-분포의 임계값은 $\pm 2.262$입니다. 이 차이는 작은 표본에서 통계적 결론에 실질적인 영향을 미칩니다.

## 4.4.3 이표본 T-검정 (Two-sample t-Test)

이표본 t-검정은 두 독립적인 그룹의 평균을 비교하는 데 사용됩니다. 예를 들어, 신약 그룹과 위약 그룹의 평균 반응을 비교하거나, 남성과 여성의 평균 점수를 비교할 때 사용합니다.

가설은 $H_0: \mu_1 = \mu_2$ (또는 동등하게 $H_0: \mu_1 - \mu_2 = 0$)이고, 대립 가설은 $H_A: \mu_1 \neq \mu_2$, $H_A: \mu_1 > \mu_2$, 또는 $H_A: \mu_1 < \mu_2$입니다.

이표본 t-검정에는 두 그룹의 모집단 분산이 같은지에 대한 가정에 따라 두 가지 형태가 있습니다.

### 4.4.3.1 분산 가정에 따른 검정 통계량 형태 (등분산 $s_p^2$ 사용)

**등분산 가정(equal variance assumption)** 하의 이표본 t-검정은 두 그룹의 모집단 분산이 같다고 가정합니다. 즉, $\sigma_1^2 = \sigma_2^2 = \sigma^2$입니다. 이 경우 두 표본의 정보를 결합하여 공통 분산을 추정합니다.

**합동 표본 분산(pooled sample variance)** $s_p^2$는 다음과 같이 계산됩니다.

$$s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}$$

이는 두 그룹의 표본 분산을 자유도를 가중치로 하여 가중 평균한 값입니다. 합동 분산은 더 많은 정보를 활용하므로 각 그룹의 분산을 개별적으로 추정하는 것보다 안정적입니다.

검정 통계량은 다음과 같습니다.

$$t = \frac{(\bar{x}_1 - \bar{x}_2) - 0}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$

이 통계량은 귀무 가설 하에서 자유도 $df = n_1 + n_2 - 2$인 t-분포를 따릅니다. 자유도가 각 그룹에서 1씩 감소하여 총 2가 줄어드는 이유는 두 개의 평균을 추정하는 데 두 개의 제약 조건이 사용되기 때문입니다.

**비등분산(unequal variance)** 상황에서는 Welch's t-test를 사용합니다. 이 방법은 등분산 가정을 하지 않으며, 검정 통계량은 다음과 같습니다.

$$t = \frac{(\bar{x}_1 - \bar{x}_2) - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$

자유도는 Welch-Satterthwaite 공식을 사용하여 계산하며, 일반적으로 정수가 아닙니다. Welch's t-test는 등분산 가정이 의심스러울 때 더 안전한 선택이며, 현대 통계 소프트웨어에서는 기본 옵션으로 사용되는 경우가 많습니다.

## 4.4.4 짝지어진 T-검정 (Paired t-Test)

짝지어진 t-검정은 동일한 개체나 매우 유사한 개체 쌍에서 두 번의 측정이 이루어진 경우에 사용됩니다. 이는 측정 사이에 자연스러운 짝이 존재하는 상황을 다룹니다.

### 4.4.4.1 짝지어진 데이터 분석의 필요성 및 원리

짝지어진 데이터는 다음과 같은 상황에서 발생합니다. 첫째, **전후 비교(before-after comparison)** 에서 같은 개체를 처치 전후로 측정하는 경우입니다. 예를 들어, 환자의 혈압을 약물 투여 전후로 측정하거나, 학생의 성적을 교육 프로그램 전후로 측정하는 경우입니다. 둘째, **매칭된 쌍(matched pairs)** 에서 의도적으로 유사한 특성을 가진 개체들을 짝지어 서로 다른 처치를 적용하는 경우입니다. 예를 들어, 일란성 쌍둥이에게 서로 다른 식단을 적용하는 연구입니다.

짝지어진 데이터의 핵심은 각 쌍 내에서 두 측정값이 독립적이지 않다는 점입니다. 같은 사람의 전후 측정값은 그 사람의 기본 특성 때문에 상관관계를 갖습니다. 이러한 상관 구조를 무시하고 이표본 t-검정을 사용하면 통계적 검정력이 크게 감소합니다.

짝지어진 t-검정의 원리는 각 쌍에 대해 차이를 계산한 후, 이 차이값들을 대상으로 단일 표본 t-검정을 수행하는 것입니다. $i$번째 쌍에 대해 $d_i = x_{1i} - x_{2i}$로 차이를 정의하면, 가설은 $H_0: \mu_d = 0$ (평균 차이가 0이다)가 되고, 검정 통계량은 다음과 같습니다.

$$t = \frac{\bar{d} - 0}{s_d/\sqrt{n}}$$

여기서 $\bar{d}$는 차이값들의 평균이고, $s_d$는 차이값들의 표준편차이며, $n$은 쌍의 개수입니다. 이 통계량은 자유도 $n - 1$인 t-분포를 따릅니다.

### 4.4.4.2 개체 간 변동성 (Subject-to-Subject Variability) 제거

짝지어진 t-검정의 가장 큰 장점은 **개체 간 변동성(subject-to-subject variability)**을 제거한다는 점입니다. 이는 통계적 검정력을 크게 향상시킵니다.

개체 간 변동성은 서로 다른 개체들 사이의 고유한 차이를 의미합니다. 예를 들어, 혈압 연구에서 사람들은 기본적으로 서로 다른 혈압 수준을 가지고 있습니다. 이러한 개인 차이는 처치의 효과와는 무관하지만, 이표본 t-검정에서는 이것이 오차로 포함되어 검정의 민감도를 떨어뜨립니다.

짝지어진 설계에서는 각 개체를 자기 자신의 대조군으로 사용함으로써 개체 간 변동성을 완전히 제거합니다. 차이값 $d_i = x_{1i} - x_{2i}$를 계산하면, 각 개체의 기본 수준은 상쇄되고 처치의 순수한 효과만 남습니다. 이는 마치 각 개체가 자신만의 작은 실험을 수행하는 것과 같습니다.

수학적으로, 차이값의 분산 $\text{Var}(d_i) = \text{Var}(x_{1i} - x_{2i}) = \text{Var}(x_{1i}) + \text{Var}(x_{2i}) - 2\text{Cov}(x_{1i}, x_{2i})$입니다. 같은 개체의 측정값들은 양의 상관관계를 가지므로 ($\text{Cov}(x_{1i}, x_{2i}) > 0$), 차이값의 분산은 두 분산의 합보다 작아집니다. 이는 더 작은 표준 오차를 의미하며, 결과적으로 더 좁은 신뢰 구간과 더 강력한 검정력을 제공합니다.

실제로 같은 데이터를 짝지어진 설계로 분석할 때와 독립 이표본으로 분석할 때 결과가 크게 달라질 수 있습니다. 짝지어진 분석이 유의한 결과를 보이는 반면, 이표본 분석은 유의하지 않을 수 있습니다. 따라서 데이터에 자연스러운 짝 구조가 있다면 반드시 짝지어진 t-검정을 사용해야 합니다.

---

# 4.5 통계적 검정의 조건 확인 및 비모수적 대안

t-검정과 같은 모수적 검정 방법들은 데이터가 특정 조건을 만족한다는 가정 하에서 개발되었습니다. 이러한 가정들이 심각하게 위배되면 검정 결과가 신뢰할 수 없게 됩니다. 따라서 통계 분석을 수행하기 전에 가정들이 합리적으로 만족되는지 확인하는 것이 중요합니다. 이 절에서는 주요 가정들을 확인하는 방법과 가정이 위배될 때 사용할 수 있는 비모수적 대안을 다룹니다.

## 4.5.1 정규성 검정 (Normality Test) 방법

t-검정의 가장 기본적인 가정은 데이터가 정규 분포를 따르거나, 표본 크기가 충분히 커서 중심 극한 정리에 의해 표본 평균이 근사적으로 정규 분포를 따른다는 것입니다. 정규성 가정을 확인하는 방법은 크게 시각적 방법과 통계적 검정 방법으로 나뉩니다.

### 4.5.1.1 시각적 확인 방법 (Histogram, Q-Q Plot)

시각적 방법은 데이터의 분포 형태를 직관적으로 파악할 수 있게 해주며, 정규성으로부터의 이탈 패턴을 쉽게 식별할 수 있습니다.

**히스토그램(Histogram)** 은 데이터의 분포를 막대 그래프로 표현합니다. 정규 분포를 따르는 데이터는 종 모양의 대칭적인 형태를 보입니다. 히스토그램을 통해 분포의 치우침(skewness), 첨도(kurtosis), 다중 봉우리(multimodality) 등을 파악할 수 있습니다. 그러나 히스토그램의 형태는 구간(bin)의 개수와 너비에 민감하게 변할 수 있으므로, 여러 설정을 시도해보는 것이 좋습니다.

**Q-Q 플롯(Quantile-Quantile Plot)** 은 정규성을 평가하는 더 정교한 시각적 도구입니다. Q-Q 플롯은 관측된 데이터의 분위수를 이론적 정규 분포의 분위수와 비교하여 산점도로 표현합니다. 데이터가 정규 분포를 따른다면 점들이 45도 직선(y = x) 위에 거의 놓이게 됩니다.

![[Pasted image 20251017185138.png]]

![[Pasted image 20251017185210.png]]

Q-Q 플롯의 해석은 다음과 같은 패턴을 통해 이루어집니다. 점들이 직선 위에 거의 놓이면 정규성이 만족됩니다. 점들이 곡선 형태를 보이면 분포가 치우쳐 있음을 의미합니다. 예를 들어, S자 형태의 곡선은 분포가 왼쪽으로 치우친 것을, 역 S자 형태는 오른쪽으로 치우친 것을 나타냅니다. 양 끝에서 직선으로부터 벗어나는 패턴은 꼬리가 두껍거나(heavy-tailed) 얇은(light-tailed) 분포를 시사합니다.

Q-Q 플롯은 히스토그램보다 정규성으로부터의 미묘한 이탈을 탐지하는 데 더 효과적입니다. 특히 표본 크기가 중간 정도일 때 유용하며, 어떤 종류의 비정규성이 있는지를 시각적으로 명확히 보여줍니다.

### 4.5.1.2 통계적 검정 방법 (Shapiro-Wilk, Kolmogorov-Smirnov)

통계적 검정 방법은 정규성에 대한 객관적인 P-값을 제공하여, 정규성 가정의 타당성을 정량적으로 평가할 수 있게 합니다.

**Shapiro-Wilk 검정**은 정규성을 평가하는 가장 강력한(powerful) 검정 방법 중 하나입니다. 이 검정은 관측값들의 순서 통계량과 정규 분포 하에서 기대되는 값들 사이의 상관관계를 측정하여 검정 통계량 $W$를 계산합니다. $W$는 0과 1 사이의 값을 가지며, 1에 가까울수록 정규성이 높음을 의미합니다.

Shapiro-Wilk 검정의 가설은 $H_0$: 데이터가 정규 분포를 따른다, $H_A$: 데이터가 정규 분포를 따르지 않는다입니다. P-값이 유의 수준(일반적으로 0.05)보다 작으면 정규성 가정을 기각합니다. 이 검정은 특히 작은 표본에서 효과적이며, 표본 크기가 약 2,000 이하일 때 권장됩니다.

**Kolmogorov-Smirnov 검정(K-S test)**은 관측된 누적 분포 함수와 이론적 정규 분포의 누적 분포 함수 사이의 최대 수직 거리를 검정 통계량으로 사용합니다. 이 검정은 정규성뿐만 아니라 다른 분포에 대한 적합도 검정에도 사용할 수 있는 범용적인 방법입니다.

K-S 검정은 Shapiro-Wilk 검정보다 검정력이 낮은 편이며, 특히 분포의 꼬리 부분에서의 이탈을 탐지하는 데 덜 민감합니다. 그러나 큰 표본에서는 여전히 유용하게 사용됩니다.

정규성 검정을 해석할 때 주의할 점이 있습니다. 표본 크기가 매우 크면 정규 분포로부터의 사소한 이탈도 통계적으로 유의하게 나타날 수 있습니다. 이러한 경우 중심 극한 정리 덕분에 t-검정은 여전히 타당할 수 있으므로, 통계적 검정 결과와 함께 시각적 방법을 병행하여 실질적인 비정규성의 정도를 판단해야 합니다. 반대로 표본 크기가 매우 작으면 검정의 검정력이 낮아 실제로 정규성이 위배되어도 탐지하지 못할 수 있습니다.

## 4.5.2 등분산성 검정 (Equal Variance Test) 방법

이표본 t-검정에서 등분산 가정(두 그룹의 모집단 분산이 같다는 가정)이 만족되는지 확인하는 것도 중요합니다. 분산이 크게 다른데 등분산을 가정하면 1종 오류율이 명목 수준을 벗어날 수 있습니다.

### 4.5.2.1 F-Test 및 Bartlett's/Levene Test

**F-검정(F-test)**은 두 그룹의 분산을 비교하는 가장 기본적인 방법입니다. 검정 통계량은 두 표본 분산의 비율로 정의됩니다.

$$F = \frac{s_1^2}{s_2^2}$$

여기서 $s_1^2$와 $s_2^2$는 각각 첫 번째와 두 번째 그룹의 표본 분산이며, 일반적으로 더 큰 분산을 분자에 놓습니다. 귀무 가설 $H_0: \sigma_1^2 = \sigma_2^2$ 하에서 이 통계량은 자유도 $(n_1 - 1, n_2 - 1)$인 F-분포를 따릅니다.

그러나 F-검정은 정규성 가정에 매우 민감합니다. 데이터가 정규 분포에서 벗어나면 F-검정의 결과를 신뢰할 수 없게 됩니다. 따라서 정규성이 의심스러운 상황에서는 다른 검정 방법을 사용하는 것이 바람직합니다.

**Bartlett's 검정**은 두 개 이상의 그룹에서 분산의 동질성을 검정할 수 있도록 F-검정을 확장한 방법입니다. 이 검정은 각 그룹의 분산과 합동 분산의 비율에 기반한 카이제곱 검정 통계량을 사용합니다. 그러나 Bartlett's 검정 역시 정규성 가정에 매우 민감하며, 정규성이 위배되면 1종 오류율이 크게 증가할 수 있습니다.

**Levene's 검정**은 정규성 가정에 덜 민감한 등분산성 검정 방법입니다. Levene's 검정의 핵심 아이디어는 원래 데이터 대신 각 관측값과 그룹 중앙값(또는 평균) 사이의 절대 편차를 사용하는 것입니다. 즉, $z_{ij} = |x_{ij} - \tilde{x}_i|$를 계산한 후, 이 편차 값들에 대해 ANOVA를 수행합니다.

Levene's 검정은 비정규 데이터에서도 비교적 안정적인 성능을 보이므로, 실무에서는 F-검정이나 Bartlett's 검정보다 Levene's 검정을 더 선호하는 경향이 있습니다. 특히 데이터가 치우쳐 있거나 이상치가 있을 때 유용합니다.

등분산성 검정 결과를 해석할 때도 주의가 필요합니다. P-값이 유의 수준보다 크다고 해서 분산이 완전히 같다는 것을 증명하는 것은 아닙니다. 단지 등분산을 기각할 만한 충분한 증거가 없다는 의미입니다. 또한 표본 크기가 작으면 검정의 검정력이 낮아서 실제로 분산이 다르더라도 탐지하지 못할 수 있습니다. 실무적으로는 등분산성이 의심스러울 때 Welch's t-test를 사용하는 것이 더 안전한 접근입니다.

## 4.5.3 비모수적 검정 방법 (Non-parametric Methods)

모수적 검정의 가정들이 심각하게 위배되거나, 데이터가 순위나 범주와 같이 정규 분포를 가정할 수 없는 형태일 때는 비모수적 검정 방법을 사용해야 합니다. 비모수적 방법은 분포에 대한 강한 가정 없이 사용할 수 있으며, 이상치에 대해서도 강건(robust)합니다.

### 4.5.3.1 Wilcoxon 순위 합 검정 (Rank-sum test)의 역할

**Wilcoxon 순위 합 검정(Wilcoxon rank-sum test)** 또는 **Mann-Whitney U 검정**은 두 독립 그룹을 비교하는 비모수적 방법으로, 이표본 t-검정의 비모수적 대안입니다. 이 검정은 두 그룹의 분포가 같은지, 특히 위치(중앙값)가 같은지를 평가합니다.

Wilcoxon 순위 합 검정의 기본 원리는 원래 데이터 값 대신 순위(rank)를 사용하는 것입니다. 먼저 두 그룹의 모든 관측값을 합쳐서 크기 순으로 정렬합니다. 그 다음 각 관측값에 순위를 부여합니다. 가장 작은 값은 순위 1, 두 번째로 작은 값은 순위 2를 받는 식입니다. 동점이 있는 경우 평균 순위를 부여합니다.

검정 통계량은 한 그룹(일반적으로 표본 크기가 작은 그룹)의 순위 합입니다. 귀무 가설 $H_0$: 두 그룹의 분포가 같다 하에서, 각 그룹의 순위 합의 기대값을 계산할 수 있습니다. 관측된 순위 합이 이 기대값으로부터 크게 벗어나면 귀무 가설을 기각합니다.

표본 크기가 작을 때는 순위 합의 정확한 분포를 사용하지만, 표본 크기가 충분히 크면(각 그룹에서 약 10 이상) 검정 통계량을 표준화하여 정규 근사를 사용합니다. 표준화된 검정 통계량은 다음과 같습니다.

$$Z = \frac{W - E[W]}{\sqrt{\text{Var}(W)}}$$

여기서 $W$는 순위 합이고, $E[W]$와 $\text{Var}(W)$는 귀무 가설 하에서의 기대값과 분산입니다.

Wilcoxon 순위 합 검정의 장점은 여러 가지입니다. 첫째, 정규성 가정이 필요 없습니다. 데이터가 어떤 분포를 따르든 사용할 수 있습니다. 둘째, 이상치에 강건합니다. 순위만 사용하므로 극단값이 있어도 그 영향이 제한적입니다. 셋째, 순서형 데이터에도 적용할 수 있습니다. 예를 들어, "매우 불만족", "불만족", "보통", "만족", "매우 만족"과 같은 리커트 척도 데이터에도 사용 가능합니다.

반면 단점도 있습니다. 첫째, 정규성이 만족될 때는 t-검정보다 검정력이 약간 낮습니다. 그러나 정규성이 위배될 때는 오히려 더 높은 검정력을 보일 수 있습니다. 둘째, 순위로 변환하면서 원래 데이터의 정보 일부가 손실됩니다. 예를 들어, 1, 2, 100이라는 값과 1, 2, 3이라는 값의 순위는 같지만 원래 값의 차이는 큽니다.

**짝지어진 데이터의 비모수적 대안**으로는 **Wilcoxon 부호 순위 검정(Wilcoxon signed-rank test)** 이 있습니다. 이는 짝지어진 t-검정의 비모수적 버전으로, 각 쌍의 차이를 계산한 후 차이의 절댓값에 순위를 부여하고, 원래 부호를 다시 붙여서 검정을 수행합니다.

실무적으로 비모수적 방법을 선택할 때의 지침은 다음과 같습니다. 표본 크기가 작고($n < 30$) 정규성이 의심스러우면 비모수적 방법을 우선 고려합니다. 데이터에 명백한 이상치가 있거나 분포가 심하게 치우쳐 있으면 비모수적 방법이 더 적절합니다. 순서형 데이터의 경우 비모수적 방법이 유일한 선택입니다. 그러나 표본 크기가 충분히 크고 정규성이 합리적으로 만족되면 t-검정과 같은 모수적 방법이 더 효율적입니다.

정규성 검정과 등분산성 검정, 그리고 비모수적 대안을 종합적으로 고려하면, 통계 분석의 타당성을 확보하고 데이터의 특성에 가장 적합한 방법을 선택할 수 있습니다. 가정을 확인하는 과정은 단순한 형식적 절차가 아니라, 데이터를 깊이 이해하고 올바른 결론에 도달하기 위한 필수적인 단계입니다.

