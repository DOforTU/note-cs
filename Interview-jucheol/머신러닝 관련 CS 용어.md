
**REST API** - **Fast API**로 만든 HTTP기반이고 서버와 클라이언트가 데이터를 주고 받는 설계 원칙이다. 

RAG - LLM과 검색 엔진을 결합하여 외부 문서, DB를 실시간으로 검색하고 그 결과를 바탕으로 답변을 생성하는 AI 아키텍쳐

LangChain - 대규모 언어 모델을 활용한 애플리케이션 개발을 쉽게 만들어주는 오픈소스 프레임워크이다. (LangChain은 "프레임워크"이지만, 개발자는 파이썬에서 "라이브러리"처럼 import해서 사용합니다. 즉, 두 개념이 동시에 적용된다고 볼 수 있습니다.)

파인튜닝 - 이미 학습된 AI 모델에 특정 데이터셋을 추가로 학습시켜, 원하는 도메인이나 테스크에 맞게 성능을 최적화하는 과정

LLM - 대규모 텍스트(언어) 데이터로 학습된 인공지능 언어 모델 <GPT, BERT, PaLM 등이 있음

AI - 인간의 지능적 행동을 컴퓨터가 수행하는 기술 <머신러닝, 딥러닝, 자연어처리, 데이터 분석 등이 있음> 챗봇, 추천 시스템, 예측 모델 등 활용가능

Docker - 애플리케이션을 컨테이너라는 격리된 환경에 패키징 -> 어디서나 일관된 환경에서 실행할 수 있게 해주는 오픈소스 플랫폼

EC2 - AWS에서 제공하는 가상 서버 서비스 (클라우드 인스턴스)

#### 머신러닝 (딥러닝 포함) 수학 관한 질문 및 답변

- CNN은 합성곱 층, 풀링 층, 밀집 층으로 구성되어있다. 이미지 처리와 패턴 인식에 성능을 보여주는 신경망이며 합성곱 층에서 이루어짐. 입력 이미지와 작은 크기의 필터(커널) 간의 합성곱 연산을 통해 새로운 특정 맵을 생성. 합성곱 레이어는 이미지의 지역적 특성(local feature - 직선이면 직선 곡선이면 곡선) 을 분석하여 확률로 리턴하는 역할. 합성곱 층이 깊어질 수록 복잡한  이미지를 분류할 수 있다. 커널과 stride(보폭)은 합성곱 층의 출력층의 크기를 조절하는 요소. 피처 맵의 크기가 크면 복잡한 이미지를 분석할 수 있지만 연산량이 많아서 오래 걸리면 부정적인 요소가 됨. 적절한 크기가 중요. 이미지의 픽셀수가 많을수록 디테일한 이미지가 된다. 피처맵의 크기가 크면 feature의 디테일을 표현할 수 있지만, 연산량이 많아져 적절한 크기를 찾는게 중요. stride가 1일 경우 한칸 씩 움직이며 합성곱 연산을 함. 커널의 크기가 같아도 보폭에 따라 피처 맵의 크기가 달라짐. 이 둘은 연산량과 모델의 정확도 사이에서 밸런스를 맞춰야함.
  
- RNN은 연속적인 데이터를 가지고 순서를 고려하여 분석, 예측하며, 앞 단계의 출력을 다음 단계의 입력에 반영하여 이전 정보를 기억하여 활용한다. 레이어를 깊게 쌓으면 더 복잡한 패턴이나 장기 의존성을 학습할 수 있다. 단어예측, 문장생성, 시계열 예측 등 널리 사용된다. 
  
- Pytorch - 페이스북에서 개발, 동적 연산 그래프이며, 코드가 실행될 때 그래프가 생성, 디버깅과 실험이 쉽고 직관적인 장점을 가졌다. 빠른 프로토타이핑 강점, 자연어 처리,  
  
- Tensorflow - 구글에서 개발, 그래프 기반 연산을 정의하며, 복잡한 모델과 대규모 분산 학습에 강점입니다. Keras는 텐서플로우의 공식 고수준 API로, 직관적이고 쉬운 신경망 설계가 가능하다. 

- GAN - 딥러닝에서 데이터를 생성하는 데 사용되는 대표적인 생성 모델이다. 두 개의 신경망인 생성자와 판별자가 서로 경쟁하며 함께 발전하는 모델입니다. 생성자는 진짜처러머 보이는 가짜 데이터를 생성하고, 판별자는 실제 데이터인지, 생성자가 만든 데이터인지 구별합니다. 

- crossentropyloss - 손실함수이며, 효율적인 계산을 하는 손실함수 라이브러리이다.
  
- optimizer - 신경망의 학습과정에서 발생하는 문제를 해결하기 위한 기법들 (adam이 흔한 옵티마이저 모델)

#### 통계적 개념
-  귀무가설 - 통계적 검정에서 기본적으로 "차이가 없다", "효과가 없다"는 전제를 세우는 가설.
  
-  대립가설 - 귀무가설을 기각한다는 의미, 새로운 주장을 입증하기위해 귀무가설을 검증하고 통계적으로 반박해야 대립가설이 신뢰를 받을 수 있다. (P-값이 작게 나오면 기각)

-  선형회귀 (직선 / 선형 연속적인 숫자값) - 독립변수와 종속변수간의 선형관계를 분석하여 최적의 회귀선을 찾아낸다. 
	y=mx +b 
	경사하강법 - 최적화 기법 / 최적의 매개변수 값을 지정 / 비용함수 (예측한 값과 실제 값 사이의 차이 측정) 를 사용하여 평균 제곱 오차를 사용한다. 기울기가 낮아지는 방향으로 찾아간다.
	등분산성이 중요함 분산이 동일, 비슷한 경우 선형회귀 예측력이 타당. 분류는 극단값에 영향을 받아 별로임.

-  로지스틱 회귀 (분류 문제 / 범주) - 어떤 변수간의 상관관계를 통해 비어있는 부분을 예측할때사용하는 회귀 분석 방법(이항 분류 문제에서 사용), S자 형태의 확률분포로 데이터를 최적화함. 이진분포도 잘 최적화함.  
   극단적인 값에 영향 없음 -> 시그모이드 (확률분포 이름) 함수. 이진분류와 같은 경우 확률과 같이 중요하게 생각하는게 Odds 승산비이다. P를 1-P로 나눈 값 (일어날 확률 P) -> 승산비 
   Odds에 로그를 취하면 logit이 된다. 이를 그래프로 하면 선형의 일차함수가 된다. 로짓과 선형함수가 합쳐서 로지스틱 회귀가 된다. 시그모이드 함수와 선형함수와 그 둘을 매개하는 로짓의 관계를 아는 것이 핵심. 

결론 회귀는 연속적인 출력 변수를 예측하는데 사용 / 분류는 이산적인 출력 변수를 예측하는데 사용

전기 사용량 예측 공모전에서 회귀용 모델을 사용 숫자를 예측하는 경우이기 때문